{
    "model_id": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
    "nb_device": 2,
    "epochs": 1,
    "device": "cuda",
    "fast_run": true,
    "eval_limit": 10,
    "model_name": "tiny-llama-1.1b",
    "hyperparameters": { 
        "learning_rate" : {"min" : -10,"max" : -1,"type" : "exp"},
        "lora_rank" : {"min" : 2,"max" : 32,"type" : "int"},
        "grad_batches" : {"min" : 0,"max" : 16,"type" : "int"},
        "lora_alpha" : {"min" : 16,"max" : 64,"type" : "int"},
        "lora_dropout" : {"min" : 0,"max" : 0.5,"type" : "float"},
        "weight_decay" : {"min" : 0,"max" : 0.5,"type" : "float"} 
        },
    "models":{
        "TinyLlama/TinyLlama-1.1B-Chat-v1.0":"tiny-llama-1.1b",
        "meta-llama/Meta-Llama-3.1-8B":"Llama-3.1-8B"

    },
    "experiment": {
        "model_id": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
        "nb_device": 2,
        "epochs": 1,
        "device": "cuda",
        "fast_run": false,
        "eval_limit": 100,
        "calls": 50,
        "historic_file": "analysis/analysis2.json",
        "model_name": "tiny-llama-1.1b"
    }

}
